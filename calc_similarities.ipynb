{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dcbc566-cc6b-4f57-88d5-e1d06dac8f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calculate lexical similarity between embeddings\n",
    "\"\"\"\n",
    "\n",
    "__author__ = 'Christin Beck'\n",
    "__created__ = '20.07.2023'\n",
    "\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy.linalg import norm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e831d57a-54a8-497b-b5dc-72b1860ee7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA A100-PCIE-40GB\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14bded44-1a53-4044-a337-7c0091d6deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_path = '../embeddings/hist-bert/'\n",
    "\n",
    "embeddings_last = embeddings_path + 'swadesh_embeddings_last.npy'\n",
    "\n",
    "embeddings = np.load(embeddings_last)\n",
    "\n",
    "\n",
    "meta_file = embeddings_path + 'swadesh_meta.tsv'\n",
    "\n",
    "meta = pd.read_csv(meta_file, sep='\\t', quotechar='\\0', encoding='utf8') #quotation marks in data (would be read in as string delimiter otherwise and there is incomplete quotation in the data)\n",
    "\n",
    "concepts = pd.DataFrame(meta, columns=['Concept']).values.flatten().tolist() \n",
    "\n",
    "corpora = pd.DataFrame(meta, columns=['Corpus']).values.flatten().tolist()  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bf1304f-6caa-4abf-86e2-ec436e3a1947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Baum', 'Berg', 'Ei', 'Fisch', 'Frau', 'Fuß', 'Hund', 'Kopf', 'Sonne', 'Vogel']\n"
     ]
    }
   ],
   "source": [
    "#calculate usage matrices for each target word for MHG, eNHG, NHG\n",
    "\n",
    "mhg = ['rem-corralled-20161222.tsv']\n",
    "enhg = ['ref-mlu.tsv', 'ref-rub.tsv', 'ref-up.tsv']\n",
    "nhg = ['dta_1700-1799', 'dta_1800-1899', 'dta_1900-1999']\n",
    "\n",
    "target_words = sorted(set(concepts))\n",
    "print(target_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc83b28-62e2-4188-8b43-706594bf36a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#files for inter-concept similarities at each stage\n",
    "sim_mhg = open('inter_simliarities_mhg.tsv', 'w')\n",
    "sim_mhg.write('Similarities\\tBaum\\tBerg\\tEi\\tFisch\\tFrau\\tFuß\\tHund\\tKopf\\tSonne\\tVogel\\n')\n",
    "\n",
    "sim_enhg = open('inter_simliarities_enhg.tsv', 'w')\n",
    "sim_enhg.write('Similarities\\tBaum\\tBerg\\tEi\\tFisch\\tFrau\\tFuß\\tHund\\tKopf\\tSonne\\tVogel\\n')\n",
    "\n",
    "sim_nhg = open('inter_simliarities_nhg.tsv', 'w')\n",
    "sim_nhg.write('Similarities\\tBaum\\tBerg\\tEi\\tFisch\\tFrau\\tFuß\\tHund\\tKopf\\tSonne\\tVogel\\n')\n",
    "\n",
    "#intra-concept similarities (similarities over time)\n",
    "sim_intra = open('intra_similarities_time.tsv', 'w')\n",
    "sim_intra.write('Target\\tME\\tEN\\tAVG\\tt-test\\tp-value\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cae22d1-0b4d-4a2f-ba2c-075f95db3f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_embeddings_mhg = []\n",
    "avg_embeddings_enhg = []\n",
    "avg_embeddings_nhg = []\n",
    "\n",
    "#calculate usage matrix for each concept at each time stage\n",
    "for target in target_words:\n",
    "    usage_mhg = []\n",
    "    usage_enhg = []\n",
    "    usage_nhg = []\n",
    "    for i, word in enumerate(concepts):\n",
    "        if word == target:\n",
    "            if corpora[i] in mhg:\n",
    "                usage_mhg.append(embeddings[i])\n",
    "            elif corpora[i] in enhg:\n",
    "                usage_enhg.append(embeddings[i])\n",
    "            elif corpora[i] in nhg:\n",
    "                usage_nhg.append(embeddings[i])\n",
    "\n",
    "    #get average embedding for each concept at each stage\n",
    "    avg_emb_mhg = np.average(np.array(usage_mhg), axis=0)   \n",
    "    avg_emb_enhg = np.average(np.array(usage_enhg), axis=0)\n",
    "    avg_emb_nhg = np.average(np.array(usage_nhg), axis=0)\n",
    "    avg_embeddings_mhg.append(avg_emb_mhg)\n",
    "    avg_embeddings_enhg.append(avg_emb_enhg)\n",
    "    avg_embeddings_nhg.append(avg_emb_nhg)\n",
    "\n",
    "\n",
    "    \n",
    "for i, target in enumerate(target_words):\n",
    "    sim_mhg.write(target + '\\t')\n",
    "    sim_enhg.write(target + '\\t')\n",
    "    sim_nhg.write(target + '\\t')\n",
    "    \n",
    "    inter_mhg_all= []\n",
    "    inter_enhg_all = []\n",
    "    inter_nhg_all = []\n",
    "    \n",
    "    #inter-concept similarity\n",
    "    for j in range(0,len(target_words)):\n",
    "        inter_mhg = np.dot(avg_embeddings_mhg[i],avg_embeddings_mhg[j])/(norm(avg_embeddings_mhg[i])*norm(avg_embeddings_mhg[j]))\n",
    "        inter_enhg = np.dot(avg_embeddings_enhg[i],avg_embeddings_enhg[j])/(norm(avg_embeddings_enhg[i])*norm(avg_embeddings_enhg[j]))\n",
    "        inter_nhg = np.dot(avg_embeddings_nhg[i],avg_embeddings_nhg[j])/(norm(avg_embeddings_nhg[i])*norm(avg_embeddings_nhg[j]))\n",
    "\n",
    "        sim_mhg.write(str(inter_mhg) + '\\t')\n",
    "        sim_enhg.write(str(inter_enhg) + '\\t')\n",
    "        sim_nhg.write(str(inter_nhg) + '\\t')\n",
    "        \n",
    "        inter_mhg_all.append(inter_mhg)\n",
    "        inter_enhg_all.append(inter_enhg)\n",
    "        inter_nhg_all.append(inter_nhg)\n",
    "        \n",
    "    sim_mhg.write('\\n')\n",
    "    sim_enhg.write('\\n')\n",
    "    sim_nhg.write('\\n')  \n",
    "\n",
    "    \n",
    "    inter_mhg_all = np.array(inter_mhg_all)\n",
    "    inter_enhg_all = np.array(inter_enhg_all)\n",
    "    inter_nhg_all = np.array(inter_nhg_all)\n",
    "    \n",
    "\n",
    "    #inter average distribution\n",
    "    inter_avg_distr = np.average([inter_mhg_all, inter_enhg_all, inter_nhg_all], axis=0)\n",
    " \n",
    "    #intra-concept similarity\n",
    "    intra_me = np.dot(avg_embeddings_mhg[i],avg_embeddings_enhg[i])/(norm(avg_embeddings_mhg[i])*norm(avg_embeddings_enhg[i]))\n",
    "    intra_en = np.dot(avg_embeddings_enhg[i],avg_embeddings_nhg[i])/(norm(avg_embeddings_enhg[i])*norm(avg_embeddings_nhg[i]))\n",
    "    \n",
    "    #t-test for testing for significant differences between inter- and intra-concept similarities\n",
    "    intra_avg = (intra_me + intra_en)/2\n",
    "    t_inter_avg, p_inter_avg = stats.ttest_1samp(a=inter_avg_distr, popmean = intra_avg) \n",
    "    \n",
    "    sim_intra.write(target + '\\t' + str(intra_me) + '\\t' + str(intra_en) + '\\t' + str(intra_avg) + '\\t' + str(round(t_inter_avg,8)) + '\\t' + str(round(p_inter_avg,8)) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
